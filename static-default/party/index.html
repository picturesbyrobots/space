<!DOCTYPE html>
<meta name=viewport content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<link rel=stylesheet href="/style.css">

<div id=room></div>
<canvas id=glRoom></canvas>
<canvas id=glPlayerView></canvas>
<iframe id=overlay src=overlay.html></iframe>
<script type=module>

import * as THREE from '/deps/three/build/three.module.js'
import { GLTFLoader } from '/deps/three/examples/jsm/loaders/GLTFLoader.js'
import { BufferGeometryUtils } from '/deps/three/examples/jsm/utils/BufferGeometryUtils.js'
import Service from '/space/js/Service.js'
import RTCPeer from '/space/js/RTCPeer.js'
import {initBuilder, useActors, useActiveScene, useAnimation } from '/hmlt/setBuilder.js'
import RTCLoopback from '/space/js/RTCLoopback.js'

const isIOS = !!navigator.platform.match(/iPhone|iPod|iPad/);

Service.get('docent', docent => {});

const hqs = location.hash
  .substr(1)
  .split('&')
  .filter(v => v)
  .map(c => c.split('=').map(decodeURIComponent))
  .reduce((params, [k, v]) => (params[k] = v, params), {});


const createSoundPlayer = (ac, destination) => {
  // iOS is currently crashing the tab when loading audio buffers. Quick fix.
  if (isIOS)
    return;

  const soundPromises = {};
  const playingSounds = {};

  const update = state => {
    for (const k in playingSounds) {
      const sound = playingSounds[k];
      if (state.k && state.k.playTime) {
        if (state[k].volume != sound.gain.gain.value)
          sound.gain.gain.setTargetAtTime(state[k].volume, ac.currentTime, 0.1);
        if (state[k].playTime == sound.playTime)
          continue;
      }
      delete playingSounds[k];
      sound.gain.gain.setTargetAtTime(0, ac.currentTime, 1.5);
      if (sound.source)
        sound.source.stop(ac.currentTime + 15);
    }
    for (const k in state) {
      if (playingSounds[k]) {
      } else if (!('playTime' in state[k])) {
        // Preload!
        getSound(k);
      } else {
        const sound = playingSounds[k] = {
          playTime: state[k].playTime,
          source: null,
          gain: ac.createGain(),
        };
        sound.gain.connect(destination);
        getSound(k).then(buf => {
          if (sound != playingSounds[k])
            return;
          const source = ac.createBufferSource();
          source.buffer = buf;
          source.loop = true;
          source.start(ac.currentTime, Math.max(0, ((Date.now() - sound.playTime) / 1000) % buf.duration));
          source.connect(sound.gain);
          sound.source = source;
          sound.gain.gain.setValueAtTime(0, ac.currentTime);
          sound.gain.gain.setTargetAtTime(state[k].volume, ac.currentTime, 0.2);
        });
      }
    }
  }
  
  const getSound = (url) => {
    return soundPromises[url] || (soundPromises[url] = 
      fetch(url)
        .then(r => r.arrayBuffer())
        .then(ab => {
          if (ac.decodeAudioData.length > 1) {
            return new Promise((resolve, reject) => {
              ac.decodeAudioData(ab, resolve, reject);
            });
          }
          return ac.decodeAudioData(ab)
        })
    );
  }

  window.addEventListener('unload', () => {
    update({});
  });

  Service.get('knobs', knobs => {
    knobs.observe('hmlt_sound', state => {
      update(state);
    });
  });
}

const createStatsTracker = () => {
  let ws;
  Service.get('ws', x => ws = x);
  return {
    fpsHistory: [],
    frames: null,
    startTime: null,
    begin() {
      if (!this.startTime) {
        this.startTime = +new Date();
        this.frames = 0;
        setTimeout(() => {
          const delta = +new Date() - this.startTime;
          const fps = this.frames / (delta / 1000)
          this.recordFps(fps);
          try {
          ws.send({ type: "debug.fps", body: fps });
          } catch(e) {}
          this.startTime = null;
        }, 1000);
      }
      this.frames++;
    },
    end() {
    },
    recordFps(fps) {
      this.fpsHistory.push(fps);
      if (this.fpsHistory.length > 10)
        this.fpsHistory.shift();
      if (this.fpsHistory.length < 10)
        return;
      const sortedFps = this.fpsHistory.slice().sort();
      const middle = (sortedFps.length + 1) / 2;
      const median = sortedFps[Math.floor(middle)];
      if (median < 29) {
        this.onPerformanceNeeded();
        this.fpsHistory.length = 5;
      }
      if (median > 50) {
        this.onPerformanceGood();
        this.fpsHistory.length = 5;
      }
    },
  };
};
const stats = createStatsTracker();

// Based on code by Adam Quinn (https://github.com/agquinn01)
const createSky = () => {
  const sky = new THREE.Group();
  for (let i = 0; i < 8; i++) {
    const opacity = Math.random() * 0.75 + 0.25;
    const starGeometries = [];
    for (let j = 0; j < 200; j++){
      const starGeometry = new THREE.SphereBufferGeometry(Math.random() * 1.5 + 0.5);
      const angle = Math.random() * Math.PI * 2;
      const distanceFromCenter = Math.random() * 2000;
      starGeometry.translate(
        Math.cos(angle) * distanceFromCenter,
        Math.random() * 107,
        Math.sin(angle) * distanceFromCenter,
      );
      starGeometries.push(starGeometry);
    }

    const starMaterial = new THREE.MeshBasicMaterial( {color: 0xffff00, transparent: true } );
    const starGroup = new THREE.Mesh(BufferGeometryUtils.mergeBufferGeometries(starGeometries), starMaterial);

    starGroup.onBeforeRender = () => {
      starMaterial.opacity = (opacity + motion * (Math.sin(performance.now() / 1000 + i / 2.) * 0.5));
    };

  }
  sky.position.y = 500;
  return sky;
};

const buildGlRoom = (canvas, playerCanvas, config) => {
  const scene = new THREE.Scene();
  const playerScene = new THREE.Scene();
  const camera = new THREE.PerspectiveCamera(60);
  camera.far = 10000;
  camera.rotation.order = 'YXZ';

  const listener = new THREE.AudioListener();
  const sounds = createSoundPlayer(listener.context, listener.gain);

  // Work around for missing echo cancellation on many kinds of audio:
  // https://crbug.com/687574
  if (navigator.userAgent.indexOf('Chrome') != -1 || navigator.userAgent.indexOf('Firefox') != -1) {
    const loopbackDestination = listener.context.createMediaStreamDestination();
    const loopbackEl = document.createElement('audio');
    const loopback = new RTCLoopback(stream => {
      listener.gain.disconnect(listener.context.destination);
      listener.gain.connect(loopbackDestination);
      loopbackEl.srcObject = loopback.outputStream;
      gestureWrangler.playVideo(loopbackEl);
    });

    loopback.setInputStream(loopbackDestination.stream);
  }

  gestureWrangler.playAudioContext(listener.context);
  camera.add(listener);
  const renderer = new THREE.WebGLRenderer({
    canvas,
    alpha: false,
    antialias: true,
    powerPreference: 'high-performance',
  });
  renderer.setClearColor(new THREE.Color().setHSL(0.5, 0.7, 0.01), 1);
  renderer.physicallyCorrectLights = true;

  const playerCamera = new THREE.PerspectiveCamera(30);
  playerCamera.rotation.order = 'YXZ';
  playerCamera.rotation.y = Math.PI;
  playerCamera.position.z -= 14;
  playerCamera.position.y -= -6;
  const playerRenderer = new THREE.WebGLRenderer({
    canvas: playerCanvas,
    alpha: true,
    antialias: false,
    powerPreference: 'high-performance',
  });
  playerRenderer.setClearColor(renderer.clearColor);

  

  const guests = {};
  let mediaStream = null;

  scene.add(createSky());

  const updateBalloons = [];
  


  
  let set_config = "hmltConfig.js"


  
  
  let hmlt_scene  = initBuilder(scene,set_config,camera,renderer,gestureWrangler, listener, config )
  let [hasActorWithId, setActorId, clearActorRole, updateMediaStream] = useActors()
  let hmlt_animate = useAnimation()





  

  let downscale = 1;
  const resize = () => {
    renderer.setSize(
      canvas.clientWidth * devicePixelRatio / downscale,
      canvas.clientHeight * devicePixelRatio / downscale, false);
    camera.aspect = canvas.width / canvas.height;
    camera.updateProjectionMatrix();

    playerRenderer.setSize(
      playerCanvas.clientWidth * devicePixelRatio,
      playerCanvas.clientHeight * devicePixelRatio, false);
    playerCamera.aspect = playerCanvas.width / playerCanvas.height;
    playerCamera.updateProjectionMatrix();
  };
  window.addEventListener('resize', resize);

  stats.onPerformanceNeeded = () => {
    if (downscale < 3) {
      downscale++;
      resize();
    }
  }

  stats.onPerformanceGood = () => {
    if (downscale > 1) {
      downscale--;
      resize();
    }
  }

  const headMaterial = new THREE.ShaderMaterial( {
    transparent: true,
    clipping: true,
    side: THREE.DoubleSide,
    uniforms: {
      t: { value: 0 },
      map: { type: 't', value: null },
      aspect: { value: 1 },
    },
    vertexShader: `
      #include <common>
      #include <uv_pars_vertex>
      #include <uv2_pars_vertex>
      #include <clipping_planes_pars_vertex>

      varying vec2 p;
      // varying vec3 norm;

      void main() {
        #include <begin_vertex>
        #include <project_vertex>
        #include <clipping_planes_vertex>
        p = uv*2.-1.;
        // norm = normalize(normalMatrix * normal);
        gl_Position = projectionMatrix * modelViewMatrix * vec4( position, 1.0 );
      }
    `,

    fragmentShader: `
      #include <common>
      #include <clipping_planes_pars_fragment>

      varying vec2 p;
      // varying vec3 norm;
      uniform sampler2D map;
      uniform float t;
      uniform float aspect;
      void main() {
        #include <clipping_planes_fragment>
        vec2 uv = p * 1.;
        uv.x /= aspect;
        uv *= cos(uv * PI / 8.) * 1.;
        uv = uv/2.+.5;
        gl_FragColor = texture2D(map, uv);

        float bri = 1. - pow(distance(p, vec2(0.0)) * 1.2 - 0.1 - sin(p.x * (p.y+0.5) * 2. + t) * 0.1, 9.);
        gl_FragColor *= 1.0-step(bri, 0.5);
        gl_FragColor.rgb *= bri;
      }
    `,
  } );

  const posAudioParams = {
    refDistance: 0,
    rolloffFactor: 0,
  };
  let audienceGain = listener.context.createGain();
  audienceGain.connect(listener.gain);

  const getOrCreateGuest = (id, remoteGuest) => {
    let guest = guests[id];
    if (guest)
      return guest;

    const geometry = new THREE.BoxBufferGeometry(2.5, 2.5, 2.5);
    const material = new THREE.MeshPhongMaterial( { color: 0xaaaaaa, emissive: 0x777700 } );
    const cube = new THREE.Mesh( geometry, material );

    const videoPanel = new THREE.Mesh(
      new THREE.CylinderBufferGeometry(3.5, 3.5, 5, 64, 1, true, Math.PI*0.25 * 3., Math.PI/2.).scale(1, 1, 0.5).translate(0, 0, -0.4),
      headMaterial.clone(),
    );
    videoPanel.onBeforeRender = () => {
      videoPanel.material.uniforms.t.value = performance.now() / 1000;
    };

    const head = new THREE.Group();
    head.add(cube);
    head.add(videoPanel);
    head.position.y = 6.4;
    head.rotation.order = 'YXZ';


    const body = new THREE.Mesh(
      new THREE.CylinderBufferGeometry(.9, .6, 4, 64),
      new THREE.MeshPhongMaterial( { color: 0xaaaaaa, emissive: 0x555555 } )
    );
    body.position.y = 2;

    const group = new THREE.Group();
    group.add(head);
    group.add(body);

    if (id === 'self') {
      playerScene.add(group);
      group.add(playerCamera);
    } else {
      scene.add(group);
    }

    const videoEl = document.createElement('video');
    videoEl.playsInline = true;
    if (!sessionStorage.noPositionalSound)
      videoEl.muted = true;

    let posSound;

    const videoTexture = new THREE.VideoTexture(videoEl);
    videoTexture.minFilter = THREE.LinearFilter;
    videoTexture.magFilter = THREE.LinearFilter;
    videoTexture.format = THREE.RGBFormat;
    videoTexture.offset.set(-0.25, 0);
    videoPanel.material.uniforms.map.value = videoTexture;
    const setSize = () => {
      videoPanel.material.uniforms.aspect.value = videoEl.videoWidth / videoEl.videoHeight;
    }
    videoEl.addEventListener('resize', () => {
      setSize();
    });
    videoEl.addEventListener('playing', () => {
      setSize();
      head.add(videoPanel);
    });
    videoEl.addEventListener('paused', () => {
      // head.remove(videoPanel);
    });

    const onVideoMute = e => {
      // head.remove(videoPanel);
    };

    const onVideoUnmute = e => {
      head.add(videoPanel);
    };

    let videoTrack, audioTrack;

    const updateTracks = () => {
        const tracks = [videoTrack, audioTrack].filter(t => t);
        const stream = tracks.length ? (videoEl.srcObject || new MediaStream(tracks)) : null;
        if (videoEl.srcObject != stream)
          videoEl.srcObject = stream;
        if (stream) {
          const oldTracks = new Set(stream.getTracks());
          for (const track of tracks) {
            if (!oldTracks.has(track))
              stream.addTrack(track);
            else
              oldTracks.delete(track);
          }
          for (const track of oldTracks)
            stream.removeTrack(track);
          gestureWrangler.playVideo(videoEl);
        }
        if (audioTrack) {
          try {
            if (sessionStorage.noPositionalSound || isIOS) {
            } else if (!posSound) {
              posSound = new THREE.PositionalAudio(listener);
              posSound.setRefDistance(posAudioParams.refDistance);
              posSound.setRolloffFactor(posAudioParams.rolloffFactor);
              posSound.setDistanceModel('exponential');
              posSound.setDirectionalCone(120, 230, 0.8);
              posSound.rotation.y = Math.PI;
              posSound.gain.disconnect();
              posSound.gain.connect(audienceGain);
              videoPanel.add(posSound);
            }
            if (posSound)
              posSound.setMediaStreamSource(stream);
          } catch (e) {
            console.log(e);
            videoEl.muted = false;
          }
        } else if (posSound) {
          try {
            posSound.getOutput().disconnect();
            posSound.disconnect();
          } catch(e){}
          posSound = null
        }
    };

    const ret = (guests[id] = {
      group, head, body, posSound,
      destroy() {
        videoEl.srcObject = null;
        videoEl.load();
        try {
          posSound.getOutput().disconnect();
          posSound.disconnect();
        } catch(e){}
      },
      get videoTrack() { return videoTrack; },
      set videoTrack(newVideoTrack) {
        if (newVideoTrack == videoTrack)
          return;
        if (videoTrack) {
          videoTrack.removeEventListener('mute', onVideoMute);
          videoTrack.removeEventListener('unmute', onVideoUnmute);
        }
        videoTrack = newVideoTrack;
        if (videoTrack) {
          videoTrack.addEventListener('mute', onVideoMute);
          videoTrack.addEventListener('unmute', onVideoUnmute);
        }
        if (videoTrack && !videoTrack.muted)
          onVideoUnmute();
        else
          onVideoMute();
        updateTracks();
      },
      get audioTrack() { return audioTrack; },
      set audioTrack(newAudioTrack) {
        if (newAudioTrack == audioTrack)
          return;
        audioTrack = newAudioTrack;
        updateTracks();
      },
    });

    ret.videoTrack = remoteGuest.videoTrack;
    ret.audioTrack = remoteGuest.audioTrack;
    updateTracks();

    if (joinSound) {
      const joinSource = THREE.AudioContext.getContext().createBufferSource();
      joinSource.buffer = joinSound;
      joinSource.connect(posSound.getOutput());
      setTimeout(() => {
        joinSource.start();
      }, 1000);
    }

    return ret;
  };

  let projectorId = null;
  let ownActorName = null;

  const updateGuest = (id, remoteGuest) => {
    
    // it's hacks all the way down ;-) 
    if(remoteGuest.state.role && remoteGuest.state.role.includes('actor'))
    {
      let [_, actor_name] = remoteGuest.state.role.split("::")
      setActorId(actor_name, id)
      if (id == 'self')
        ownActorName = actor_name;
      const guest = guests[id];
      if (guest) {
        removeGuest(id, true);
        updateMedia(id, guest);
      }
      return;
    }
    clearActorRole(id);
    if (id == 'self') {
      ownActorName = '';
    }
    if (remoteGuest.state.role == 'cast') {
      projectorId = id;
      return;
    }
    const guest = getOrCreateGuest(id, remoteGuest);
    const { state } = remoteGuest;
    guest.group.rotation.y = -state.look[0];
    guest.head.rotation.x = -state.look[1];

    guest.group.position.x = state.position[0];
    guest.group.position.z = -state.position[1];
    guest.group.position.y = state.position[2];
  }

  const updateMedia = (id, { videoTrack, audioTrack }) => {
    updateMediaStream(id, new MediaStream([videoTrack, audioTrack].filter(t => t)));

    if (id == projectorId) {
      projector.setStream(new MediaStream([videoTrack, audioTrack].filter(t => t)));
      return;
    }
    const guest = guests[id];
    if (!guest) {
      return;
    }
    guest.videoTrack = videoTrack;
    guest.audioTrack = audioTrack;
  };

  const removeGuest = id => {
    const guest = guests[id];
    if (!guest)
      return;

    if (partSound) {
      const partSource = THREE.AudioContext.getContext().createBufferSource();
      partSource.buffer = partSound;
      partSource.connect(guest.posSound.getOutput());
      partSource.start();
    }

    guest.group.parent.remove(guest.group);
    guest.destroy();
    delete guests[id];
  };

  const cubez = [];
  

  const byteFreqData = new Uint8Array(1024);

  const createProjector = (size) => {
    const group = new THREE.Group();
    const mesh = new THREE.Mesh(new THREE.PlaneBufferGeometry(size * (16/9), size));
    mesh.position.y = size/2;
    group.add(mesh);

    const light = new THREE.PointLight(0xffffff, 100, size + 30);
    light.position.z = 30;
    light.position.y = size/2;
    group.add(light);
      
    const posSound = new THREE.PositionalAudio(listener);
    posSound.setRefDistance(10);
    posSound.setRolloffFactor(1.5);
    posSound.setDistanceModel('exponential');
    posSound.setDirectionalCone(120, 230, 0.2);
    posSound.rotation.y = Math.PI;
    mesh.add(posSound);

    const videoEl = document.createElement('video');
    videoEl.playsInline = true;
    videoEl.muted = true;
    posSound.setMediaElementSource(videoEl);

    const videoTexture = new THREE.VideoTexture(videoEl);
    videoTexture.minFilter = THREE.LinearFilter;
    videoTexture.magFilter = THREE.LinearFilter;
    videoTexture.format = THREE.RGBFormat;
    // videoTexture.offset.set(-0.25, 0);
    mesh.material = new THREE.MeshPhongMaterial({
      color:0xffffff,
      side: THREE.DoubleSide,
      map: videoTexture,
    });
    // videoEl.addEventListener('playing', () => {
    //   videoPanel.material.uniforms.aspect.value = videoEl.videoWidth / videoEl.videoHeight;
    //   head.add(videoPanel);
    // });
    // videoEl.addEventListener('paused', () => {
    //   head.remove(videoPanel);
    // });

    // scene.add(group);
    return {
      group,
      setStream: stream => {
        videoEl.srcObject = stream;
        gestureWrangler.playVideo(videoEl);
        posSound.setMediaStreamSource(stream);
        posSound.source.connect(musicAnalyser);
      }
    };
  };

  let projector = createProjector(40);
  projector.group.position.z = -75;
  projector.group.position.x = -180;
  projector.group.rotation.y = Math.PI / 2;

  const isEffectivelyVisible = obj => {
    if (!obj)
      return true;
    if (!obj.visible)
      return false;
    return isEffectivelyVisible(obj.parent);
  };

  const draw = ({ now, look, position }) => {
    let onStage = false;
    if (ownActorName) {
      const obj = scene.getObjectByName(ownActorName);
      if (obj) {

        let {height} = obj.geometry.parameters
        obj.add(camera);

        if (isEffectivelyVisible(obj))
          onStage = true;

        camera.position.set(0, 0.5 * height, -1.25 * height);
        camera.rotation.set(-Math.PI/11, Math.PI, 0);
        camera.fov = 50;
        camera.updateProjectionMatrix();
      }
    } else {
      scene.add(camera);
      camera.position.set(position[0], 6 + position[2], -position[1]);
      camera.rotation.set(-look[1], -look[0], 0);
      camera.fov = 60;
      camera.updateProjectionMatrix();
    }

    if (onStage) {
      if (!sessionStorage.onStage)
          sessionStorage.onStage = true;
    } else {
      if (sessionStorage.onStage)
        delete sessionStorage.onStage;
    }


    hmlt_animate()

    renderer.render(scene, camera);

    playerRenderer.render(playerScene, playerCamera);
  };

  const clearGuests = () => {
    for (const k in guests) {
      removeGuest(k);
    }
  };

  Service.get('knobs', knobs => {
    knobs.observe('posAudio.refDistance', refDistance => {
      posAudioParams.refDistance = refDistance;
      for (const k in guests)
        guests[k].posSound && guests[k].posSound.setRefDistance(refDistance * 50);
    }, 1);
    knobs.observe('posAudio.rolloffFactor', rolloffFactor => {
      posAudioParams.rolloffFactor = rolloffFactor;
      for (const k in guests)
        guests[k].posSound && guests[k].posSound.setRolloffFactor(rolloffFactor * 10);
    }, 1);
    let audienceMuted = false;
    knobs.observe('guestsMuted', v => {
      audienceMuted = v;
      audienceGain.gain.setTargetAtTime(v ? 0 : 1, THREE.AudioContext.getContext().currentTime, 0.1);
      if (v) {
        setTimeout(() => {
          if (audienceMuted)
            audienceGain.disconnect();
        }, 1000);
      } else {
        audienceGain.connect(listener.gain);
      }
    }, false);
  });

  resize();
  return {
    draw, updateGuest, removeGuest, updateMedia, clearGuests
  };
}

const buildRoom = (el, config) => {
  let player;
  const glRoom = buildGlRoom(document.getElementById('glRoom'), document.getElementById('glPlayerView'), {
    roomEl: el,
    ...config
  });

  const ret = {
  };

  let animationFrame;
  let lastLook, lastPosition;
  const equalVectors = (a, b) => {
    if (!(a && b))
      return false;
    if (a.length != b.length)
      return false;
    for (let i = 0; i < a.length; i++) {
      if (a[i] != b[i])
        return false;
    }
    return true;
  };
  const draw = rawNow => {
    stats && stats.begin();
    const now = rawNow + timeOffset;
    player.stepPhysics();
    const { position, look } = player;
    glRoom.draw({ now, position, look });
    stats && stats.end();
    animationFrame = requestAnimationFrame(draw);
  };

  Service.get('room', room => {
    const ac = room.ac;
    player = room.player;

    room.join();
    room.observe('update', (id, state) => {
      if (state)
        glRoom.updateGuest(id, state);
      else
        glRoom.removeGuest(id);
    });

    room.observe('updateMedia', (id, guest) => {
      glRoom.updateMedia(id, guest);
    });

    room.observe('clear', () => {
      glRoom.clearGuests();
    });

    glRoom.clearGuests();
    for (const k in room.guests)
      glRoom.updateGuest(k, room.guests[k]);

    if (!animationFrame)
      animationFrame = requestAnimationFrame(draw);

    /*
    fetch('/sounds/join.mp3')
      .then(r => r.arrayBuffer())
      .then(ab => ac.decodeAudioData(ab))
      .then(buf => {
        joinSound = buf;
      });

    fetch('/sounds/part.mp3')
      .then(r => r.arrayBuffer())
      .then(ab => ac.decodeAudioData(ab))
      .then(buf => {
        partSound = buf;
      });
    */

  });

  Service.get('hamlet', show => {
    show.observe('curtainUp', data => {

      Service.get('room', room => {
      glRoom.clearGuests();
      for (const k in room.guests)
        glRoom.updateGuest(k, room.guests[k]);

      })

    })
  })

  return ret;
}

let gestureWrangler;
let timeOffset;
let musicAnalyser;
let musicReactivity = 0;
let motion = 0;

let joinSound;
let partSound;

const start = () => {
  Service.get('knobs', knobs => {
    knobs.observe('world.musicReactivity', v => {
      musicReactivity = v;
    }, 1);
    knobs.observe('world.motion', v => {
      motion = v;
    }, 1);
  });

  Service.get('gestureWrangler', gw => {
    gestureWrangler = gw;
  });

  let userMedia;
  Service.get('userMedia', um => {
    userMedia = um;
    userMedia.start();

    // services are so bad right now please restore my sanity
    if (Service.window.qs && Service.window.qs.tkt) {
      Service.get('knobs', knobs => {
        knobs.observe('perf.tickleUserMedia', on => {
          um.debugRestart();
        }, false);
        knobs.observe('perf.requiredVideoMute', on => {
          document.getElementById('glPlayerView').style.display = on ? 'none' : '';
          um.setRequiredVideoMute(on);
        }, false);
        knobs.observe('perf.requiredAudioMute', on => {
          um.setRequiredAudioMute(on);
        }, false);
      });
    }
  });

  Service.window.addEventListener('keydown', e => {
    switch (e.keyCode) {
      case 77: // m
        userMedia.toggleAudioMuted();
        break;
      case 86: // v
        userMedia.toggleVideoMuted();
        break;
      default:
        return; // without preventing default
    }
    e.preventDefault();
  });

  return fetch('/config.json')
    .then(r => r.json())
    .then(config => {
      timeOffset = new Date() - config.zeroTime

      let builtRoom = false;
      Service.get('room', room => {
        THREE.AudioContext.setContext(room.ac);
        musicAnalyser = room.ac.createAnalyser();
        if (!builtRoom) {
          buildRoom(document.getElementById('room'), config);
          builtRoom = true;
        }
      });
    })
};

if (Service.window.waitForGesture === true) {
  window.startOnGesture = start;
} else {
  start();
}

if (window != Service.window) {
  window.addEventListener('focus', e => {
    Service.window.focus();
  });
}

</script>
